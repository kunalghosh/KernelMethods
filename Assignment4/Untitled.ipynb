{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11421cc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#######################################################################\n",
    "# Function to implement one-vs-all SVM\n",
    "# For SVM we use the scikit learn's SVM implementation\n",
    "#######################################################################\n",
    "from __future__ import division\n",
    "import pdb\n",
    "import itertools\n",
    "\n",
    "from IPython.core.debugger import Tracer\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.ion()\n",
    "\n",
    "# Load data\n",
    "X_train = np.loadtxt(\"./data/X_train.txt\")\n",
    "X_test  = np.loadtxt(\"./data/X_test.txt\")\n",
    "y_train = np.loadtxt(\"./data/y_train.txt\").astype(np.int32)\n",
    "y_test  = np.loadtxt(\"./data/y_test.txt\").astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cost(W,X,Y,C):\n",
    "    \"\"\"\n",
    "    W = [K,D] K = number of classes, D = number of dimensions\n",
    "    Y = true classes {1,...,10}\n",
    "    \"\"\"\n",
    "    [K,D] = W.shape \n",
    "    [N,D] = X.shape\n",
    "    if not hasattr(cost, \"negInfMask\"):\n",
    "        cost.negInfMask = np.arange(N)*K + (Y - 1)\n",
    "        # Y values are in {1,...,10} but array indices\n",
    "        # in python are in {0,...,9}\n",
    "\n",
    "    normW = 0.5 * np.sum(np.linalg.norm(W,axis=1)**2)\n",
    "    # wYiXi = np.diag(np.dot(W[Y-1,:], X.T))\n",
    "    # wYiXi = np.einsum('ij,ji->i',W[Y-1,:], X.T)\n",
    "    wYiXi = np.einsum('ij,ij->i',W[Y.astype(np.int32)-1,:], X)\n",
    "    wJXi  = np.dot(X,W.T) \n",
    "    # wJXi  = np.einsum('ij,kj->ik',X,W) \n",
    "    # We mask j = Yi for each i with -np.inf\n",
    "    # before that we need to convert (i,Yj) to \n",
    "    # row major array index\n",
    "    np.put(wJXi, cost.negInfMask, -np.inf)\n",
    "    max_wJXi = np.max(wJXi, axis=1)\n",
    "\n",
    "    slack = 1 - wYiXi + max_wJXi\n",
    "    costVal = normW + C * np.sum(np.maximum(0, slack))  \n",
    "    # return (costVal, slack) \n",
    "    return costVal \n",
    "\n",
    "def subgradient(W,xi,yi,sum_X,C):\n",
    "    \"\"\"\n",
    "    sum_X = [1,D]\n",
    "    \"\"\"\n",
    "    [K,D] = W.shape\n",
    "    \n",
    "    Wxi = np.dot(W,xi.T)\n",
    "    Wxi_yi = np.copy(Wxi[yi-1])\n",
    "    Wxi[yi-1]=-np.inf # in next step we want argmax j!=yi\n",
    "    j_star = np.argmax(Wxi)\n",
    "\n",
    "    deltaW = np.copy(W)\n",
    "\n",
    "    if 1 - Wxi_yi + Wxi[j_star] >= 0:\n",
    "        for j in xrange(K):\n",
    "            if j == yi:\n",
    "                deltaW[j,:] = W[j,:] - C*sum_X\n",
    "            elif j == j_star:\n",
    "                deltaW[j,:] = W[j,:] + C*sum_X\n",
    "            else:\n",
    "                # deltaW[j,:] == W[j,:] from initialization\n",
    "                # of deltaW\n",
    "                pass\n",
    "    deltaW /= np.linalg.norm(deltaW,2,axis=1).reshape(K,1)\n",
    "    return deltaW\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "C = 10\n",
    "iters = 15000\n",
    "[N,D]  = X_train.shape\n",
    "[M,Dt] = X_test.shape \n",
    "\n",
    "assert D == Dt, \"Train and Test data must have the same number of features (dimensions)\"\n",
    "# If we don't have a particular class in the training set\n",
    "# Then we can't learn to classify it. Using this logic \n",
    "# we get the set of K - classes which we need to train as\n",
    "# follows.\n",
    "labels = np.unique(y_train)\n",
    "K = len(labels)\n",
    "\n",
    "# Random initilization of the Weight matrix [K,D]\n",
    "W = np.random.random((K,D))\n",
    "costList = np.zeros((iters+1, 1))\n",
    "costList[0] = cost(W,X_train,y_train,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.67 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit cost(W,X_train,y_train,C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sum_X = np.sum(X_train, axis=0)\n",
    "for iterCnt in xrange(iters):\n",
    "    iterCnt += 1\n",
    "    randIdx = np.random.randint(N)\n",
    "    xi,yi = X_train[randIdx, :], y_train[randIdx]\n",
    "    deltaW = subgradient(W, xi, yi, sum_X, C)\n",
    "    tk = 1.0/(10 * C * (iterCnt ** 0.25))\n",
    "    W -= tk * deltaW\n",
    "    costList[iterCnt] = cost(W,X_train,y_train,C)\n",
    "    Tracer()()\n",
    "    if iterCnt % 1000 == 0:\n",
    "        print(\"{} - Cost is : {}\".format(iterCnt, np.mean(costList[iterCnt-10:iterCnt])))\n",
    "\n",
    "plt.scatter(range(len(costList)), costList)\n",
    "plt.show()\n",
    "\n",
    "ytest_pred  = np.dot(X_test, W.T) \n",
    "ytrain_pred = np.dot(X_train, W.T)\n",
    "\n",
    "ytest_pred = np.argmax(ytest_pred, axis=1) + 1 \n",
    "ytrain_pred = np.argmax(ytrain_pred, axis=1) + 1\n",
    "\n",
    "assert ytrain_pred.shape == (N,), \"Count of training predictions must match the number of examples in training dataset \"\n",
    "assert ytest_pred.shape == (M,), \"Count of test predictions must match the number of examples in test dataset \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[ytest_pred, ytrain_pred, costList] = svmCombinedModel(X_train, X_test, y_train, C=10)\n",
    "print(np.sum(ytest_pred == y_test))\n",
    "print(np.sum(ytrain_pred == y_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
